#summary Описание многоуровневой системы критериев и методов оценки объектов, с помощью нее
#labels Phase-Requirements
= Оценка объектов по многоуровневой системе критериев =


== Реферат ==

Многоуровневая система критериев впервые описанна в работе [_1_]. В отличие от классических моделей принятия решений, которые исходят из предпосылки о том, что один фактор можно компенсировать другим, в многоуровневой системе критериев вводится понятие квазиконьюктивных и квазидизъюнктивных операторов агрегирования. Они оценивают объект хорошо, когда все факторых принимают хорошие значения или когда хотя бы один принимает хорошее значение соответсвенно.
Оказалось, что такой взаимный учет факторов хорошо отражает ...
Если исследователь располагает объективными или экспертными оценками некоторых объектов, то можно применить машинное обучение для определение параметров иерархической модели критериев. 
В результате обучения можно интерпретировать параметры модели: важность факторов и характер их совместного влияния (квазиконьюктивность или квазидизъюнктивность). А так же можно получать оценки для новых объектов.
В статье приведено краткое описание модели, приведен алгоритм определения параметров, даны оценки качества модели при решении задач принятия решений.

== Введение ==

Проблема?


== Постановка задачи ==

== Иерархическая система критериев ==


Условием для применения квазиконъюнктивных операторов является следующее правило: _"Для получения высокого значения оператора (близкого к единице)  необходимо, чтобы все агрегируемые критерии имели высокие значения"_

== Определение параметров модели по обучающей выборке ==

=== Проблемы ===
1. Невозможно получить функцию в явном виде => невозможно посчитать частные производные и сделать многомерную оптимизацию градиентным спуском
2. Функция неунимодальна
3. Область допустимых значений представляет из себя гиперплоскость, т.к.
sum(w__i) = 1 

Нельзя применять классические методы оптимизации.
Целе


===	Методы борьбы с неунимодальностью. Генетический алгоритм ===
Запустим оптимизацию алгоритмом, изложенным выше, из исходных точек. Этот алгоритм будет сходиться к минимуму, в произвольном случае локальному. Что-бы улучшить оценку оптимизации необходимо запускать алгоритм из других точек. 
Воспользуемся для генерации новых точек одним из ключевых методов генети-ческого алгоритма: кроссинговером. В какой-то момент случайно выберем два дерева (они будут одинаковы по форме) и разорвем их в какой-нибудь вершине. Затем возь-мем левую часть одного дерева склеим с правой частью другого и наоборот, тем са-мым получим еще два дерева и запустим из них алгоритм оптимизации. 
Тем самым мы получили ветвление. Мы останавливаем процесс генерации, ко-гда он перестает улучшать оценку МНК.

==== Параллельная реализация ===
Очевидно, что оптимизации параметров из различных точек являются независи-мыми, поэтому их можно выполнять параллельно. При этом процесс, осуществляю-щий контроль исполнения должен отслеживать лучшие оценки и отсекать оптимиза-ции согласно принципу границ.


== Что? ==
  * Что за модель? Как её читать? Почему она хорошо работает в жизни?
  * Машинное обучение? 
  * Сравнение с RVM, регрессией
  * Оценить/уметь бороться с переобучаемостю модели при машинном обучении
  	* Кроссенговер
  	* Оценка на тестовом множестве для раннего останова
  * Обеспечить масштабируемость модели при росте обучающей выборки и модели
 
== Список литературы ==
1.	Елтаренко Е.А. Оценка и выбор решений по многим критериям. М.; МИФИ, 1995.
 